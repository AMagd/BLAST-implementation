defaults:
  # Job
  n_steps: 100_000
  run_name: none
  resume_id:
  input_dir: ./data/train
  eval_dir: ./data/eval
  log_interval: 500
  save_interval: 5000
  eval_interval: 5000
  enable_profiler: False

  # Env
  channels: 4
  image_key: image
  image_size: 7
  map_key: map_centered
  map_size: 19

  # Training
  iwae_samples: 1
  kl_weight: 1.0
  adam_lr: 3.0e-4
  adam_eps: 1.0e-5
  data_seq: True
  keep_state: True
  batch_length: 50
  batch_size: 50
  device: "cuda:0"

  # Eval
  eval_batches: 21  # For unbiased eval needs to be enough to cover full episodes
  full_eval_batches: 101  # Big enough to reach episode end (xN). +1 to log last episode
  full_eval_samples: 100  # Big enough for good sampling
  full_eval_length: 50  # Fixed =batch_length
  full_eval_size: 10  # Limited by GPU mem

  # Model
  model: world
  embed_dim: 256
  embed_rnn: none
  deter_dim: 512
  stoch_dim: 30
  hidden_dim: 200
  gru_layers: 1
  image_encoder: dense
  image_encoder_layers: 3
  image_decoder: dense
  image_decoder_layers: 2
  map_stoch_dim: 30
  map_model: direct
  map_grad: False
  mem_model: none
  mem_loss_type:
  global_dim: 0

  # Optimizer
  grad_clip: 20
  image_decoder_min_prob: 0

  # Generator
  generator_run: False
  generator_env:
  generator_wait: 300
  generator_buffer: 0

top: # Top-down observations instead of agent-centric
  # Env
  channels: 8
  image_key: map_masked
  image_size: 11
  map_key: map
  map_size: 11